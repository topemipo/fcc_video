{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Import all Neccesary Libraires and Modules</h1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Query Expansion</h1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_query_generated(user_query, model=\"gpt-3.5-turbo\"):\n",
    "    system_prompt = \"\"\"You are a helpful expert research assistant. \n",
    "    Provide a plausible example answer to the user's query as if you found it in a case document.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"I believe I was wrongfully terminated from my job. What can I do?\"\n",
    "hypothetical_answer = augment_query_generated(original_query)\n",
    "joint_query = f\"{original_query} {hypothetical_answer}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Query Vector DB to return most relevant Chunks</h1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chroma_collection(chroma_collection, query_text, n_results=1):\n",
    "    \"\"\"\n",
    "    Queries a Chroma collection and returns metadata with relevance scores.\n",
    "\n",
    "    Args:\n",
    "        chroma_collection (chromadb.Collection): The Chroma collection to query.\n",
    "        query_text (str): The query text (original query + hypothetical answer) to search for.\n",
    "        n_results (int): Number of results to return. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: Retrieved metadata with relevance scores included.\n",
    "    \"\"\"\n",
    "    # Query the Chroma collection\n",
    "    results = chroma_collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=n_results,\n",
    "        include=[\"documents\", \"embeddings\", \"metadatas\", \"distances\"]  # Include distances explicitly\n",
    "    )\n",
    "\n",
    "    # Extract metadata and distances from the results\n",
    "    retrieved_metadata = results[\"metadatas\"][0]\n",
    "    retrieved_distances = results[\"distances\"][0]\n",
    "\n",
    "    # Compute relevance scores from distances\n",
    "    relevance_scores = [1 / (1 + distance) for distance in retrieved_distances]\n",
    "\n",
    "    # Add relevance scores to the metadata\n",
    "    for metadata, relevance_score in zip(retrieved_metadata, relevance_scores):\n",
    "        metadata[\"relevance_score\"] = relevance_score\n",
    "\n",
    "    return retrieved_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C14.txt\n"
     ]
    }
   ],
   "source": [
    "# implementation\n",
    "retrieved_metadata = query_chroma_collection(chroma_collection, joint_query, n_results=1)\n",
    "case_doc = retrieved_metadata[0]['source']\n",
    "print(case_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Extract txt file from directory</h1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_contents(pattern, target_filename):\n",
    "    \"\"\"\n",
    "    pattern: A glob pattern, e.g. '/path/to/*.txt'\n",
    "    target_filename: A filename we want to match in those results\n",
    "    \"\"\"\n",
    "    # Expand the pattern into all matching file paths\n",
    "    matching_files = glob.glob(pattern)  # returns a list of matching paths\n",
    "\n",
    "    for fpath in matching_files:\n",
    "        # Get the base name of the file (e.g., \"C2.txt\") and compare \n",
    "        if os.path.basename(fpath) == target_filename:\n",
    "            with open(fpath, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "\n",
    "    # If we exit the loop, the file wasn't found\n",
    "    raise FileNotFoundError(f\"File '{target_filename}' not found in the pattern '{pattern}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation\n",
    "file_content = get_file_contents(folder_path, case_doc)\n",
    "print(file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Carryout Text Summarization</h1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_with_map_reduce(file_content: str, max_length: int = 100) -> str:\n",
    "    \"\"\"\n",
    "    Summarize long text using the Map-Reduce method, preserving specific details before a list starts.\n",
    "\n",
    "    Args:\n",
    "        file_content (str): The long text to summarize.\n",
    "        max_length (int): The maximum length of the summary in tokens or words (approximation).\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text, preserving details before the first list starts.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract the section to preserve (everything before the first list starts)\n",
    "    match = re.search(r\"^(.*?)(\\n\\s*1\\.)\", file_content, re.DOTALL)\n",
    "    if match:\n",
    "        preserved_section = match.group(1).strip()\n",
    "        remaining_content = file_content[len(preserved_section):].strip()\n",
    "    else:\n",
    "        # If no list is found, treat the whole text as the preserved section\n",
    "        preserved_section = file_content.strip()\n",
    "        remaining_content = \"\"\n",
    "\n",
    "    # Step 2: Split the remaining text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,  # Adjust chunk size as needed\n",
    "        chunk_overlap=50  # Adjust overlap to preserve context\n",
    "    )\n",
    "    chunks = text_splitter.split_text(remaining_content)\n",
    "\n",
    "    # Step 3: Convert chunks into a list of Document objects\n",
    "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "    # Step 4: Initialize the LLM\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "    # Step 5: Load the Map-Reduce summarization chain\n",
    "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "    # Step 6: Invoke the chain with the documents and adjust the summary length\n",
    "    result = chain.invoke({\"input_documents\": documents, \"length\": max_length})\n",
    "\n",
    "    # Step 7: Combine the preserved section with the generated summary\n",
    "    summary = preserved_section + \"\\n\\n\" + result[\"output_text\"]\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central Inland Water Transport Corporation Limited and Another v Brojo Nath Ganguly and Another\n",
      "Supreme Court of India\n",
      "\n",
      "6 April 1986\n",
      "C.A. No. 4412 and 4413 of 1985\n",
      "The Judgment was delivered by : D. P. Madon, J.\n",
      "\n",
      "The Appeals by Special Leave granted by the Court address whether a Government company falls under the definition of \"the State\" as per Article 12 of the Constitution. The Central Inland Water Transport Corporation Limited, a government company, is owned by the Central Government and two State Governments. The Appeals challenge the termination of two employees' services by the Corporation and the validity of Rule 9(i) of the Service Discipline and Appeal Rules. The Calcutta High Court ruled that the Corporation is considered a State under Article 12 and that Rule 9(i) violates Article 14 of the Constitution. The Appeals question whether government companies can be considered part of \"the State\" and the validity of employment contracts under Article 14. The Court will review the arguments presented by both parties to determine the outcome of the Appeals.\n"
     ]
    }
   ],
   "source": [
    "summary = summarize_text_with_map_reduce(file_content, max_length=2000)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Generate Response</h1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(question, context_data):\n",
    "    \"\"\"\n",
    "    Generate a response based on the provided legal context (as a string).\n",
    "    \n",
    "    Args:\n",
    "        question (str): The user's legal question.\n",
    "        context_data (str): The full legal text to be used as context.\n",
    "\n",
    "    Returns:\n",
    "        str: A generated response summarizing relevant legal cases.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the prompt using the full context_data string\n",
    "    prompt = f\"\"\"You are a legal assistant designed to help users understand their legal situations by retrieving and summarizing relevant cases. Follow these steps STRICTLY:\n",
    "    \n",
    "    1. **Sympathize with the user** (1-2 sentences):\n",
    "       - Acknowledge their situation with empathy (e.g., \"I’m sorry to hear...\", \"This sounds difficult...\").\n",
    "    \n",
    "    2. **Retrieve and summarize a case** from the knowledge base below:\n",
    "    {context_data}\n",
    "       - Format:\n",
    "         **Case Name**: [Exact case title]\n",
    "         **Introduction**: [1-2 sentence overview: who was involved and the core issue]\n",
    "         **Details**: [Key facts/events in chronological order]\n",
    "         **Verdict**: [Court decision + outcomes like damages or policy changes]\n",
    "\n",
    "    3. **Next Steps** (3-4 bullet points):\n",
    "       - Practical actions tied to the case (e.g., \"Save emails from [date range]\")\n",
    "       - Resources (e.g., \"Contact [Agency Name] within [timeframe]\")\n",
    "    \n",
    "    Tone Rules:\n",
    "    - Professional but compassionate\n",
    "    - Zero legal jargon (avoid terms like \"plaintiff\" or \"motion\")\n",
    "    - If no matching case: \n",
    "      * Apologize briefly\n",
    "      * Provide 2-3 general steps\n",
    "      * Add: \"Every case is unique – consulting a lawyer is recommended\"\n",
    "\n",
    "    Example structure to mimic:\n",
    "    \"I’m sorry to hear about your situation. Let me share a similar case:\n",
    "    **Case Name**: Smith v. ABC Corp\n",
    "    **Introduction**: A warehouse worker fired after reporting safety issues.\n",
    "    **Details**: The employee reported violations in March 2022, was terminated April 2022 with no warning. The employer claimed budget cuts.\n",
    "    **Verdict**: Court ruled wrongful termination – $150k awarded due to retaliation evidence.\n",
    "    Next steps:\n",
    "    - Document all safety reports you filed\n",
    "    - Contact OSHA within 30 days\n",
    "    - Consult an employment lawyer\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m sorry to hear about your situation. It must be really tough dealing with the uncertainty of wrongful termination. Let me share a similar case that might help you understand how such matters can be approached:\n",
      "\n",
      "**Case Name**: Central Inland Water Transport Corporation Limited and Another v Brojo Nath Ganguly and Another\n",
      "**Introduction**: This case involved the Central Inland Water Transport Corporation Limited, a government company, and addressed the wrongful termination of two employees.\n",
      "**Details**: The employees were terminated under Rule 9(i) of the Service Discipline and Appeal Rules. The Calcutta High Court found that the corporation, being owned by the government, qualified as \"the State\" under Article 12 of the Constitution and that Rule 9(i) was in violation of Article 14, which ensures equality before the law.\n",
      "**Verdict**: The court ruled that the termination was invalid and that the rule under which the termination was made violated constitutional provisions.\n",
      "\n",
      "Next steps:\n",
      "- Gather all relevant documents such as your employment contract, any correspondence related to your termination, and performance reviews.\n",
      "- Document any instances that might suggest that the termination was unfair or illegal.\n",
      "- Consider consulting with an employment lawyer who can provide guidance based on the specifics of your case.\n",
      "- If applicable, check if your company has an internal grievance procedure that you can use to challenge your termination.\n",
      "\n",
      "Every case is unique – consulting a lawyer is recommended to get advice tailored to your specific circumstances.\n"
     ]
    }
   ],
   "source": [
    "final_response = generate_response(original_query, summary)\n",
    "print(final_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
